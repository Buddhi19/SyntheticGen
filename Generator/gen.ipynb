{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1b3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import shutil\n",
    "import random\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee0032b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main directory added to sys.path: /data/inr/llm\n"
     ]
    }
   ],
   "source": [
    "main_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))))\n",
    "sys.path.append(main_dir)\n",
    "\n",
    "print(\"Main directory added to sys.path:\", main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdd0ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = os.path.join(\n",
    "    main_dir, \"Datasets\",\"LOVEDA\", \"Train\", \"Train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b5ad6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
    "\n",
    "REAL_ROOT = Path(DATASET_DIR)\n",
    "\n",
    "# Generator checkpoints (your provided paths)\n",
    "LAYOUT_CKPT = \"/data/inr/llm/DIFF_CD/Diffusor/outputsV3/layout_d3pm_masked_sparse_80k_domain_cond\"\n",
    "LAYOUT_CHECKPOINT = 79000\n",
    "LAYOUT_DIFFUSION_TYPE = \"d3pm\"\n",
    "DOMAIN_COND_SCALE = 1.0\n",
    "\n",
    "CONTROLNET_CKPT = \"/data/inr/llm/DIFF_CD/Diffusor/outputsV3/controlnet_ratio_lora_ckpt18000_layout80000/checkpoint-112000\"\n",
    "BASE_MODEL = \"/home/nvidia/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14\"\n",
    "\n",
    "# Output synthetic dataset root (WILL CREATE LoveDA-like structure)\n",
    "# Saved under: <Diffusor root>/syntheticDataset/...\n",
    "SYNTH_ROOT = Path(main_dir) / \"DIFF_CD\" / \"Diffusor\" /\"SyntheticDataset\"\n",
    "# How many synthetic samples total to generate\n",
    "SYNTH_TOTAL = 2000\n",
    "\n",
    "# Prompt templates (domain-specific)\n",
    "PROMPTS = {\n",
    "    \"rural\": \"A high-resolution satellite image of a rural area\",\n",
    "    \"urban\": \"A high-resolution satellite image of an urban area\",\n",
    "}\n",
    "\n",
    "# Inference settings (your provided)\n",
    "IMAGE_SIZE = 1024\n",
    "NUM_STEPS_LAYOUT = 200\n",
    "NUM_STEPS_IMAGE = 50\n",
    "GUIDANCE_SCALE = 1.0\n",
    "GUIDANCE_RESCALE = 0.0\n",
    "CONTROL_SCALE = 1.0\n",
    "LORA_SCALE = 1.0\n",
    "DTYPE = \"fp16\"\n",
    "DEVICE = \"cuda:0\"\n",
    "SAMPLER = \"ddim\"\n",
    "\n",
    "# Random seed base\n",
    "SEED0 = 123\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e5f8b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do NOT \"fully balance\" per-image ratios.\n",
    "# We instead:\n",
    "#   - enforce domain quota so Rural+Synth ≈ Urban+Synth\n",
    "#   - within each domain, enforce *pixel deficit* vs a flattened target distribution\n",
    "#   - prompt ratios ONLY within safe bounds around real-domain mean μ_d,k\n",
    "\n",
    "# Target flattening within each domain:\n",
    "#   t_nonbg ∝ (pi_nonbg)^BETA, with BETA<1 => flatter => minorities get deficits => generated more\n",
    "BETA = 0.55\n",
    "\n",
    "# Extra minority prioritization factor:\n",
    "#   score_k ∝ deficit_k * (pi_k + eps)^(-GAMMA)\n",
    "GAMMA = 0.7\n",
    "\n",
    "# Safety caps: max allowed boost in the prompted ratio relative to μ_d,k (real-domain mean)\n",
    "MAX_DELTA = {\n",
    "    \"background\": 0.15,\n",
    "    \"building\": 1.20,\n",
    "    \"road\": 1.10,\n",
    "    \"water\": 0.80,\n",
    "    \"barren\": 1.00,\n",
    "    \"forest\": 0.35,\n",
    "    \"agriculture\": 0.35,\n",
    "}\n",
    "\n",
    "# Acceptance criteria (prevents \"ratio too far from average\" failures)\n",
    "FOCUS_ABS_TOL = 0.09      # |p_k - r_k| <= this\n",
    "GLOBAL_MAX_ABS = 0.32     # max_j |p_j - μ_j| <= this\n",
    "KL_MAX = 0.90             # KL(p || μ) <= this\n",
    "\n",
    "# Retry limits\n",
    "MAX_ATTEMPTS_PER_SAMPLE = 12\n",
    "\n",
    "# Class order used by your pipeline (matches DEFAULT_LOVEDA_CLASS_NAMES)\n",
    "CLASS_NAMES = [\"background\", \"building\", \"road\", \"water\", \"barren\", \"forest\", \"agriculture\"]\n",
    "K = len(CLASS_NAMES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff0fae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /data/inr/llm/DIFF_CD/Diffusor/SyntheticGen\n",
      "sample_pair: /data/inr/llm/DIFF_CD/Diffusor/SyntheticGen/src/scripts/sample_pair.py\n",
      "Synthetic dataset root: /data/inr/llm/DIFF_CD/Diffusor/SyntheticDataset\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 2) Utility: find repo root / sample_pair script\n",
    "# ---------------------------\n",
    "def find_repo_root() -> Path:\n",
    "    \"\"\"\n",
    "    Find a directory containing src/scripts/sample_pair.py\n",
    "    starting from CWD and walking up.\n",
    "    \"\"\"\n",
    "    cwd = Path(os.getcwd()).resolve()\n",
    "    candidates = [cwd] + list(cwd.parents)\n",
    "    for base in candidates:\n",
    "        p = base / \"src\" / \"scripts\" / \"sample_pair.py\"\n",
    "        if p.exists():\n",
    "            return base\n",
    "        # common alternate repo folder nesting\n",
    "        p2 = base / \"SyntheticGen\" / \"src\" / \"scripts\" / \"sample_pair.py\"\n",
    "        if p2.exists():\n",
    "            return base / \"SyntheticGen\"\n",
    "        p3 = base / \"Diffusor\" / \"src\" / \"scripts\" / \"sample_pair.py\"\n",
    "        if p3.exists():\n",
    "            return base / \"Diffusor\"\n",
    "    raise FileNotFoundError(\"Could not locate src/scripts/sample_pair.py from current path parents.\")\n",
    "\n",
    "REPO_ROOT = find_repo_root()\n",
    "SAMPLE_PAIR = REPO_ROOT / \"src\" / \"scripts\" / \"sample_pair.py\"\n",
    "print(\"Repo root:\", REPO_ROOT)\n",
    "print(\"sample_pair:\", SAMPLE_PAIR)\n",
    "print(\"Synthetic dataset root:\", SYNTH_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d373b072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real counts: {'rural': 1366, 'urban': 1156}\n",
      "Real avg valid pixels: {'rural': 696951.32, 'urban': 982431.24}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 3) Utility: mask loading and histogram (robust to raw vs indexed)\n",
    "# ---------------------------\n",
    "IGNORE_INDEX = 255\n",
    "\n",
    "def load_mask_as_indexed(mask_path: Path) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns mask in indexed format:\n",
    "      classes: 0..6, ignore: 255\n",
    "    Supports:\n",
    "      - LoveDA raw: 0=ignore, 1..7=classes\n",
    "      - already indexed: 0..6 with optional 255 ignore\n",
    "    \"\"\"\n",
    "    arr = np.array(Image.open(mask_path))\n",
    "    if arr.ndim == 3:\n",
    "        arr = arr[:, :, 0]\n",
    "\n",
    "    mx = int(arr.max())\n",
    "    mn = int(arr.min())\n",
    "\n",
    "    # Heuristic: raw LoveDA typically has values in {0..7} with 0 as ignore\n",
    "    if mx <= 7 and mn >= 0 and (0 in np.unique(arr)):\n",
    "        out = arr.astype(np.int64)\n",
    "        ignore = out == 0\n",
    "        out[ignore] = IGNORE_INDEX\n",
    "        out[~ignore] = out[~ignore] - 1\n",
    "        return out.astype(np.int64)\n",
    "\n",
    "    # treat as indexed already\n",
    "    return arr.astype(np.int64)\n",
    "\n",
    "def hist_counts(mask_idx: np.ndarray) -> np.ndarray:\n",
    "    flat = mask_idx.reshape(-1)\n",
    "\n",
    "    # Drop ignore + any out-of-range labels (prevents bincount length > K)\n",
    "    flat = flat[(flat != IGNORE_INDEX) & (flat >= 0) & (flat < K)]\n",
    "\n",
    "    return np.bincount(flat, minlength=K).astype(np.float64)\n",
    "\n",
    "def safe_kl(p: np.ndarray, q: np.ndarray, eps: float = 1e-12) -> float:\n",
    "    p = np.clip(p, eps, 1.0); p = p / p.sum()\n",
    "    q = np.clip(q, eps, 1.0); q = q / q.sum()\n",
    "    return float(np.sum(p * np.log(p / q)))\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Scan real dataset: domain counts + pixel totals\n",
    "# ---------------------------\n",
    "def domain_dirs(root: Path, domain_title: str) -> tuple[Path, Path]:\n",
    "    droot = root / domain_title\n",
    "    masks = droot / \"masks_png\"\n",
    "    imgs = droot / \"images_png\"\n",
    "    if not masks.exists():\n",
    "        for alt in [\"masks\", \"labels\", \"SegmentationClass\"]:\n",
    "            if (droot / alt).exists():\n",
    "                masks = droot / alt\n",
    "                break\n",
    "    if not imgs.exists():\n",
    "        for alt in [\"images\", \"imgs\", \"JPEGImages\"]:\n",
    "            if (droot / alt).exists():\n",
    "                imgs = droot / alt\n",
    "                break\n",
    "    return imgs, masks\n",
    "\n",
    "def scan_domain(root: Path, domain_title: str) -> dict:\n",
    "    imgs_dir, masks_dir = domain_dirs(root, domain_title)\n",
    "    mask_files = sorted([p for p in masks_dir.glob(\"*.png\")])\n",
    "    if not mask_files:\n",
    "        raise FileNotFoundError(f\"No masks found for {domain_title} under {masks_dir}\")\n",
    "    totals = np.zeros(K, dtype=np.float64)\n",
    "    valid_px_total = 0.0\n",
    "\n",
    "    for mp in mask_files:\n",
    "        m = load_mask_as_indexed(mp)\n",
    "        c = hist_counts(m)\n",
    "        totals += c\n",
    "        valid_px_total += float(c.sum())\n",
    "\n",
    "    return {\n",
    "        \"n\": len(mask_files),\n",
    "        \"totals\": totals,\n",
    "        \"valid_px_total\": valid_px_total,\n",
    "        \"avg_valid_px\": valid_px_total / max(1, len(mask_files)),\n",
    "        \"masks_dir\": str(masks_dir),\n",
    "        \"imgs_dir\": str(imgs_dir),\n",
    "    }\n",
    "\n",
    "real_r = scan_domain(REAL_ROOT, \"Rural\")\n",
    "real_u = scan_domain(REAL_ROOT, \"Urban\")\n",
    "\n",
    "print(\"Real counts:\", {\"rural\": real_r[\"n\"], \"urban\": real_u[\"n\"]})\n",
    "print(\"Real avg valid pixels:\", {\"rural\": round(real_r[\"avg_valid_px\"], 2), \"urban\": round(real_u[\"avg_valid_px\"], 2)})\n",
    "\n",
    "# Real-domain mean proportions μ_d (used for safe prompting + acceptance)\n",
    "mu_real = {\n",
    "    \"rural\": real_r[\"totals\"] / max(1.0, real_r[\"totals\"].sum()),\n",
    "    \"urban\": real_u[\"totals\"] / max(1.0, real_u[\"totals\"].sum()),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dcae09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic domain quota: {'rural': 895, 'urban': 1105} sum= 2000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 5) Domain quota: balance Rural vs Urban after coupling with original\n",
    "# ---------------------------\n",
    "nR, nU = real_r[\"n\"], real_u[\"n\"]\n",
    "\n",
    "target_per_domain = math.floor((nR + nU + SYNTH_TOTAL) / 2.0)\n",
    "\n",
    "need_r = max(0, target_per_domain - nR)\n",
    "need_u = max(0, target_per_domain - nU)\n",
    "allocated = need_r + need_u\n",
    "rem = SYNTH_TOTAL - allocated\n",
    "if rem > 0:\n",
    "    need_r += rem // 2\n",
    "    need_u += rem - rem // 2\n",
    "\n",
    "while (need_r + need_u) > SYNTH_TOTAL:\n",
    "    if need_r >= need_u and need_r > 0:\n",
    "        need_r -= 1\n",
    "    elif need_u > 0:\n",
    "        need_u -= 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "domain_quota = {\"rural\": need_r, \"urban\": need_u}\n",
    "print(\"Synthetic domain quota:\", domain_quota, \"sum=\", sum(domain_quota.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec8cfd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 6) Build LoveDA-like synthetic structure\n",
    "# IMPORTANT: we will SAVE masks in *raw LoveDA encoding* (0 ignore, 1..7 classes),\n",
    "# so LoveDADataset(remap_loveda_labels) will work without hacks.\n",
    "# ---------------------------\n",
    "def ensure_synth_structure(root: Path):\n",
    "    for dom in [\"Rural\", \"Urban\"]:\n",
    "        (root / \"Train\" / \"Train\" / dom / \"images_png\").mkdir(parents=True, exist_ok=True)\n",
    "        (root / \"Train\" / \"Train\" / dom / \"masks_png\").mkdir(parents=True, exist_ok=True)\n",
    "    (root / \"meta\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ensure_synth_structure(SYNTH_ROOT)\n",
    "\n",
    "def save_mask_raw_from_indexed(mask_idx: np.ndarray, out_path: Path):\n",
    "    \"\"\"Convert indexed (0..6, 255 ignore) -> LoveDA raw (0 ignore, 1..7 classes).\"\"\"\n",
    "    raw = np.zeros_like(mask_idx, dtype=np.uint8)\n",
    "    ignore = mask_idx == IGNORE_INDEX\n",
    "    raw[ignore] = 0\n",
    "    raw[~ignore] = (mask_idx[~ignore] + 1).astype(np.uint8)\n",
    "    Image.fromarray(raw, mode=\"L\").save(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fe4d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 7) Core math: domain-aware flattened target + pixel deficits -> class choice -> safe ratio prompt\n",
    "# ---------------------------\n",
    "EPS = 1e-12\n",
    "\n",
    "def make_flat_target(pi: np.ndarray, bg_idx: int = 0) -> np.ndarray:\n",
    "    \"\"\"Keep background proportion ~as-is, flatten only non-background via power transform.\"\"\"\n",
    "    pi = np.clip(pi, EPS, 1.0); pi = pi / pi.sum()\n",
    "    bg = float(pi[bg_idx])\n",
    "    non = pi.copy()\n",
    "    non[bg_idx] = 0.0\n",
    "    if non.sum() <= 0:\n",
    "        return pi\n",
    "    non_t = np.power(non / non.sum(), BETA)\n",
    "    non_t = non_t / non_t.sum()\n",
    "    t = np.zeros_like(pi)\n",
    "    t[bg_idx] = bg\n",
    "    t += (1.0 - bg) * non_t\n",
    "    t = t / t.sum()\n",
    "    return t\n",
    "\n",
    "def pick_focus_class(deficit: np.ndarray, pi: np.ndarray) -> int:\n",
    "    \"\"\"Deficit-based selection with extra rarity emphasis.\"\"\"\n",
    "    rarity = np.power(np.clip(pi, EPS, 1.0), -GAMMA)\n",
    "    score = deficit * rarity\n",
    "    score[0] = 0.0  # never focus background\n",
    "    s = score.sum()\n",
    "    if s <= 0:\n",
    "        w = np.power(np.clip(pi, EPS, 1.0), -1.0)\n",
    "        w[0] = 0.0\n",
    "        w = w / w.sum()\n",
    "        return int(np.random.choice(np.arange(K), p=w))\n",
    "    p = score / s\n",
    "    return int(np.random.choice(np.arange(K), p=p))\n",
    "\n",
    "def propose_ratio(domain: str, focus_k: int, t: np.ndarray, pi: np.ndarray) -> float:\n",
    "    \"\"\"Safe ratio prompt anchored to μ_real(domain,k) and capped by MAX_DELTA.\"\"\"\n",
    "    mu0 = float(mu_real[domain][focus_k])\n",
    "    if mu0 <= 0:\n",
    "        mu0 = float(pi[focus_k])\n",
    "    desired_lift = float(t[focus_k] / max(pi[focus_k], EPS))\n",
    "    name = CLASS_NAMES[focus_k]\n",
    "    cap = float(MAX_DELTA.get(name, 0.7))\n",
    "    delta = min(cap, max(0.0, 0.85 * (desired_lift - 1.0)))\n",
    "    r = mu0 * (1.0 + delta)\n",
    "    r = float(r + np.random.normal(0.0, 0.015))\n",
    "    r = float(np.clip(r, 0.01, 0.60))\n",
    "    r = float(np.clip(r, mu0 * (1.0 - 0.25), mu0 * (1.0 + cap)))\n",
    "    return r\n",
    "\n",
    "def accept_layout(domain: str, p: np.ndarray, focus_k: int, r_req: float) -> tuple[bool, dict]:\n",
    "    \"\"\"Reject \"bad generations\" characterized by ratio too far from μ or requested ratio.\"\"\"\n",
    "    mu0 = mu_real[domain]\n",
    "    max_abs = float(np.max(np.abs(p - mu0)))\n",
    "    kl = safe_kl(p, mu0)\n",
    "    focus_err = float(abs(p[focus_k] - r_req))\n",
    "    ok = (focus_err <= FOCUS_ABS_TOL) and (max_abs <= GLOBAL_MAX_ABS) and (kl <= KL_MAX)\n",
    "    return ok, {\"max_abs\": max_abs, \"kl\": kl, \"focus_err\": focus_err}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a73c074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/inr/llm/DIFF_CD/Diffusor/SyntheticDataset\n",
      "Logging to: /data/inr/llm/DIFF_CD/Diffusor/SyntheticDataset/meta/generation_log.jsonl\n",
      "Will generate 2000 synthetic samples under /data/inr/llm/DIFF_CD/Diffusor/SyntheticDataset\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 8) Generator call (sample_pair) and dataset writer\n",
    "# ---------------------------\n",
    "def run_sample_pair(tmp_out: Path, domain: str, ratios_str: str, seed: int):\n",
    "    cmd = [\n",
    "        \"python3\", str(SAMPLE_PAIR),\n",
    "        \"--layout_ckpt\", str(LAYOUT_CKPT),\n",
    "        \"--layout_checkpoint\", str(LAYOUT_CHECKPOINT),\n",
    "        \"--layout_diffusion_type\", str(LAYOUT_DIFFUSION_TYPE),\n",
    "        \"--domain\", str(domain),\n",
    "        \"--domain_cond_scale\", str(DOMAIN_COND_SCALE),\n",
    "        \"--controlnet_ckpt\", str(CONTROLNET_CKPT),\n",
    "        \"--base_model\", str(BASE_MODEL),\n",
    "        \"--save_dir\", str(tmp_out),\n",
    "        \"--ratios\", ratios_str,\n",
    "        \"--prompt\", PROMPTS[domain],\n",
    "        \"--image_size\", str(IMAGE_SIZE),\n",
    "        \"--num_inference_steps_layout\", str(NUM_STEPS_LAYOUT),\n",
    "        \"--num_inference_steps_image\", str(NUM_STEPS_IMAGE),\n",
    "        \"--guidance_scale\", str(GUIDANCE_SCALE),\n",
    "        \"--guidance_rescale\", str(GUIDANCE_RESCALE),\n",
    "        \"--control_scale\", str(CONTROL_SCALE),\n",
    "        \"--lora_scale\", str(LORA_SCALE),\n",
    "        \"--sampler\", str(SAMPLER),\n",
    "        \"--seed\", str(seed),\n",
    "        \"--dtype\", str(DTYPE),\n",
    "        \"--device\", str(DEVICE),\n",
    "    ]\n",
    "    subprocess.run(cmd, cwd=str(REPO_ROOT), check=True)\n",
    "\n",
    "def write_synth_sample(domain: str, stem: str, tmp_out: Path):\n",
    "    \"\"\"Move tmp_out outputs into SYNTH_ROOT LoveDA structure. Save mask as raw LoveDA encoding.\"\"\"\n",
    "    dom_title = \"Rural\" if domain == \"rural\" else \"Urban\"\n",
    "    img_src = tmp_out / \"image.png\"\n",
    "    msk_src = tmp_out / \"layout.png\"\n",
    "    meta_src = tmp_out / \"metadata.json\"\n",
    "\n",
    "    img_dst = SYNTH_ROOT / \"Train\" / \"Train\" / dom_title / \"images_png\" / f\"{stem}.png\"\n",
    "    msk_dst = SYNTH_ROOT / \"Train\" / \"Train\" / dom_title / \"masks_png\" / f\"{stem}.png\"\n",
    "    meta_dst = SYNTH_ROOT / \"meta\" / f\"{stem}.json\"\n",
    "\n",
    "    shutil.move(str(img_src), str(img_dst))\n",
    "\n",
    "    m_idx = np.array(Image.open(msk_src))\n",
    "    if m_idx.ndim == 3:\n",
    "        m_idx = m_idx[:, :, 0]\n",
    "    m_idx = m_idx.astype(np.int64)\n",
    "    save_mask_raw_from_indexed(m_idx, msk_dst)\n",
    "\n",
    "    if meta_src.exists():\n",
    "        shutil.move(str(meta_src), str(meta_dst))\n",
    "    else:\n",
    "        meta_dst.write_text(json.dumps({\"domain\": domain}, indent=2))\n",
    "\n",
    "    return img_dst, msk_dst, meta_dst, m_idx\n",
    "\n",
    "# ---------------------------\n",
    "# 9) Main loop: domain quota + pixel-deficit controller\n",
    "# ---------------------------\n",
    "cur = {\n",
    "    \"rural\": real_r[\"totals\"].copy(),\n",
    "    \"urban\": real_u[\"totals\"].copy(),\n",
    "}\n",
    "avg_valid_px = {\n",
    "    \"rural\": float(real_r[\"avg_valid_px\"]),\n",
    "    \"urban\": float(real_u[\"avg_valid_px\"]),\n",
    "}\n",
    "\n",
    "accepted = {\"rural\": 0, \"urban\": 0}\n",
    "manifest = []\n",
    "\n",
    "print(SYNTH_ROOT)\n",
    "\n",
    "log_path = SYNTH_ROOT / \"meta\" / \"generation_log.jsonl\"\n",
    "print(\"Logging to:\", log_path)\n",
    "\n",
    "def choose_domain(domain_quota: dict) -> str:\n",
    "    rem_r = domain_quota[\"rural\"] - accepted[\"rural\"]\n",
    "    rem_u = domain_quota[\"urban\"] - accepted[\"urban\"]\n",
    "    if rem_r <= 0 and rem_u <= 0:\n",
    "        return \"rural\"\n",
    "    if rem_r <= 0:\n",
    "        return \"urban\"\n",
    "    if rem_u <= 0:\n",
    "        return \"rural\"\n",
    "    pr = rem_r / (rem_r + rem_u)\n",
    "    return \"rural\" if random.random() < pr else \"urban\"\n",
    "\n",
    "total_to_make = sum(domain_quota.values())\n",
    "print(f\"Will generate {total_to_make} synthetic samples under {SYNTH_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95ce3d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/.local/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.6.2) or chardet (None)/charset_normalizer (3.4.4) doesn't match a supported version!\n",
      "  warnings.warn(\n",
      "INFO - Resolved layout checkpoint to: /data/inr/llm/DIFF_CD/Diffusor/outputsV3/layout_d3pm_masked_sparse_80k_domain_cond/checkpoint-79000\n",
      "INFO - Inferred --layout_size=256 from --image_size=1024 (override with --layout_size).\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/inr/llm/DIFF_CD/Diffusor/SyntheticGen/src/scripts/sample_pair.py\", line 1186, in <module>\n",
      "    main()\n",
      "  File \"/data/inr/llm/DIFF_CD/Diffusor/SyntheticGen/src/scripts/sample_pair.py\", line 1137, in main\n",
      "    images = _vae_decode(vae, latents / vae.config.scaling_factor)\n",
      "  File \"/data/inr/llm/DIFF_CD/Diffusor/SyntheticGen/src/scripts/sample_pair.py\", line 390, in _vae_decode\n",
      "    decoded = vae.decode(latents)\n",
      "  File \"/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/utils/accelerate_utils.py\", line 46, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/models/autoencoders/autoencoder_kl.py\", line 237, in decode\n",
      "    decoded = self._decode(z).sample\n",
      "  File \"/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/models/autoencoders/autoencoder_kl.py\", line 208, in _decode\n",
      "    dec = self.decoder(z)\n",
      "  File \"/data/inr/llm/.lib/diffusers/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/data/inr/llm/.lib/diffusers/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/models/autoencoders/vae.py\", line 302, in forward\n",
      "    sample = up_block(sample, latent_embeds)\n",
      "  File \"/data/inr/llm/.lib/diffusers/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/data/inr/llm/.lib/diffusers/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/models/unets/unet_2d_blocks.py\", line 2639, in forward\n",
      "    hidden_states = resnet(hidden_states, temb=temb)\n",
      "  File \"/data/inr/llm/.lib/diffusers/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/data/inr/llm/.lib/diffusers/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/models/resnet.py\", line 327, in forward\n",
      "    hidden_states = self.norm1(hidden_states)\n",
      "  File \"/data/inr/llm/.lib/diffusers/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/data/inr/llm/.lib/diffusers/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/data/inr/llm/.lib/diffusers/lib/python3.10/site-packages/torch/nn/modules/normalization.py\", line 313, in forward\n",
      "    return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
      "  File \"/data/inr/llm/.lib/diffusers/lib/python3.10/site-packages/torch/nn/functional.py\", line 2955, in group_norm\n",
      "    return torch.group_norm(\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 638.62 MiB is free. Process 3847044 has 47.40 GiB memory in use. Process 3967351 has 8.57 GiB memory in use. Process 4092921 has 8.57 GiB memory in use. Including non-PyTorch memory, this process has 14.06 GiB memory in use. Of the allocated memory 13.33 GiB is allocated by PyTorch, and 228.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['python3', '/data/inr/llm/DIFF_CD/Diffusor/SyntheticGen/src/scripts/sample_pair.py', '--layout_ckpt', '/data/inr/llm/DIFF_CD/Diffusor/outputsV3/layout_d3pm_masked_sparse_80k_domain_cond', '--layout_checkpoint', '79000', '--layout_diffusion_type', 'd3pm', '--domain', 'urban', '--domain_cond_scale', '1.0', '--controlnet_ckpt', '/data/inr/llm/DIFF_CD/Diffusor/outputsV3/controlnet_ratio_lora_ckpt18000_layout80000/checkpoint-112000', '--base_model', '/home/nvidia/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14', '--save_dir', '/data/inr/llm/DIFF_CD/Diffusor/SyntheticDataset/tmp/urban_000000_try00', '--ratios', 'barren:0.0748', '--prompt', 'A high-resolution satellite image of an urban area', '--image_size', '1024', '--num_inference_steps_layout', '200', '--num_inference_steps_image', '50', '--guidance_scale', '1.0', '--guidance_rescale', '0.0', '--control_scale', '1.0', '--lora_scale', '1.0', '--sampler', 'ddim', '--seed', '123', '--dtype', 'fp16', '--device', 'cuda:0']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mrmtree(tmp_out, ignore_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m tmp_out\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mrun_sample_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratios_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m layout_path \u001b[38;5;241m=\u001b[39m tmp_out \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m m_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(layout_path))\n",
      "Cell \u001b[0;32mIn[11], line 29\u001b[0m, in \u001b[0;36mrun_sample_pair\u001b[0;34m(tmp_out, domain, ratios_str, seed)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_sample_pair\u001b[39m(tmp_out: Path, domain: \u001b[38;5;28mstr\u001b[39m, ratios_str: \u001b[38;5;28mstr\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m      5\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(SAMPLE_PAIR),\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--layout_ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(LAYOUT_CKPT),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--device\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(DEVICE),\n\u001b[1;32m     28\u001b[0m     ]\n\u001b[0;32m---> 29\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mREPO_ROOT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/inr/llm/.lib/diffusers/lib/python3.10/subprocess.py:526\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    527\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['python3', '/data/inr/llm/DIFF_CD/Diffusor/SyntheticGen/src/scripts/sample_pair.py', '--layout_ckpt', '/data/inr/llm/DIFF_CD/Diffusor/outputsV3/layout_d3pm_masked_sparse_80k_domain_cond', '--layout_checkpoint', '79000', '--layout_diffusion_type', 'd3pm', '--domain', 'urban', '--domain_cond_scale', '1.0', '--controlnet_ckpt', '/data/inr/llm/DIFF_CD/Diffusor/outputsV3/controlnet_ratio_lora_ckpt18000_layout80000/checkpoint-112000', '--base_model', '/home/nvidia/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14', '--save_dir', '/data/inr/llm/DIFF_CD/Diffusor/SyntheticDataset/tmp/urban_000000_try00', '--ratios', 'barren:0.0748', '--prompt', 'A high-resolution satellite image of an urban area', '--image_size', '1024', '--num_inference_steps_layout', '200', '--num_inference_steps_image', '50', '--guidance_scale', '1.0', '--guidance_rescale', '0.0', '--control_scale', '1.0', '--lora_scale', '1.0', '--sampler', 'ddim', '--seed', '123', '--dtype', 'fp16', '--device', 'cuda:0']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "with open(log_path, \"a\", encoding=\"utf-8\") as flog:\n",
    "    global_i = 0\n",
    "    while (accepted[\"rural\"] + accepted[\"urban\"]) < total_to_make:\n",
    "        domain = choose_domain(domain_quota)\n",
    "\n",
    "        pi = cur[domain] / max(EPS, cur[domain].sum())\n",
    "        t = make_flat_target(pi)\n",
    "\n",
    "        rem = (domain_quota[domain] - accepted[domain])\n",
    "        plan_total = float(cur[domain].sum() + rem * avg_valid_px[domain])\n",
    "\n",
    "        deficit = np.maximum(0.0, plan_total * t - cur[domain])\n",
    "\n",
    "        focus_k = pick_focus_class(deficit, pi)\n",
    "        focus_name = CLASS_NAMES[focus_k]\n",
    "\n",
    "        r_req = propose_ratio(domain, focus_k, t, pi)\n",
    "        ratios_str = f\"{focus_name}:{r_req:.4f}\"\n",
    "\n",
    "        ok = False\n",
    "        last_metrics = None\n",
    "\n",
    "        for attempt in range(MAX_ATTEMPTS_PER_SAMPLE):\n",
    "            seed = SEED0 + (accepted[\"rural\"] + accepted[\"urban\"]) * 1000 + attempt\n",
    "            tmp_out = SYNTH_ROOT / \"tmp\" / f\"{domain}_{accepted[domain]:06d}_try{attempt:02d}\"\n",
    "            if tmp_out.exists():\n",
    "                shutil.rmtree(tmp_out, ignore_errors=True)\n",
    "            tmp_out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            run_sample_pair(tmp_out, domain, ratios_str, seed)\n",
    "\n",
    "            layout_path = tmp_out / \"layout.png\"\n",
    "            m_idx = np.array(Image.open(layout_path))\n",
    "            if m_idx.ndim == 3:\n",
    "                m_idx = m_idx[:, :, 0]\n",
    "            m_idx = m_idx.astype(np.int64)\n",
    "\n",
    "            counts = hist_counts(m_idx)\n",
    "            p = counts / max(EPS, counts.sum())\n",
    "\n",
    "            ok, metrics = accept_layout(domain, p, focus_k, r_req)\n",
    "            last_metrics = metrics\n",
    "\n",
    "            record = {\n",
    "                \"domain\": domain,\n",
    "                \"focus_class\": focus_name,\n",
    "                \"ratios\": ratios_str,\n",
    "                \"seed\": seed,\n",
    "                \"attempt\": attempt,\n",
    "                \"ok\": bool(ok),\n",
    "                \"metrics\": metrics,\n",
    "                \"p\": [float(x) for x in p.tolist()],\n",
    "            }\n",
    "            flog.write(json.dumps(record) + \"\\n\")\n",
    "            flog.flush()\n",
    "\n",
    "            if not ok:\n",
    "                shutil.rmtree(tmp_out, ignore_errors=True)\n",
    "                continue\n",
    "\n",
    "            stem = f\"{domain}_{accepted[domain]:06d}\"\n",
    "            img_dst, msk_dst, meta_dst, m_idx2 = write_synth_sample(domain, stem, tmp_out)\n",
    "\n",
    "            cur[domain] += hist_counts(m_idx2)\n",
    "\n",
    "            accepted[domain] += 1\n",
    "            global_i += 1\n",
    "\n",
    "            manifest.append({\n",
    "                \"domain\": domain,\n",
    "                \"image\": str(img_dst),\n",
    "                \"mask\": str(msk_dst),\n",
    "                \"meta\": str(meta_dst),\n",
    "                \"ratios\": ratios_str,\n",
    "                \"focus_class\": focus_name,\n",
    "                \"metrics\": last_metrics,\n",
    "            })\n",
    "\n",
    "            shutil.rmtree(tmp_out, ignore_errors=True)\n",
    "\n",
    "            if global_i % 25 == 0:\n",
    "                print(f\"[{global_i}/{total_to_make}] accepted | quotas={domain_quota} | accepted={accepted} | last={domain}/{ratios_str} metrics={last_metrics}\")\n",
    "            break\n",
    "\n",
    "        if not ok:\n",
    "            damp = 0.85\n",
    "            ratios_str = f\"{focus_name}:{(r_req*damp):.4f}\"\n",
    "            print(f\"WARNING: too many rejects for {domain}/{focus_name}. Backing off ratio to {ratios_str} and continuing.\")\n",
    "\n",
    "manifest_path = SYNTH_ROOT / \"meta\" / \"manifest.json\"\n",
    "manifest_path.write_text(json.dumps({\n",
    "    \"real_root\": str(REAL_ROOT),\n",
    "    \"synth_root\": str(SYNTH_ROOT),\n",
    "    \"synth_total\": total_to_make,\n",
    "    \"domain_quota\": domain_quota,\n",
    "    \"accepted\": accepted,\n",
    "    \"items\": manifest,\n",
    "}, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Done.\")\n",
    "print(\"Synthetic dataset:\", SYNTH_ROOT)\n",
    "print(\"Manifest:\", manifest_path)\n",
    "print(\"Accepted:\", accepted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
