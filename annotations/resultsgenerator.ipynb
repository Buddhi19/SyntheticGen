{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4c1ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /data/inr/llm/DIFF_CD/Diffusor\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import datetime\n",
    "import string\n",
    "\n",
    "ROOT = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(ROOT)\n",
    "\n",
    "print(\"ROOT:\", ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7d154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTDIR: /data/inr/llm/DIFF_CD/Diffusor/outputsV2/resultsgenerator_runs/1\n"
     ]
    }
   ],
   "source": [
    "class ARGS:\n",
    "    def __init__(self):\n",
    "        self.base_model = \"/home/nvidia/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/451f4fe16113bff5a5d2269ed5ad43b0592e9a14\"\n",
    "        self.layout_ckpt = os.path.join(ROOT , \"outputsV2\" , \"layout_ddpm_export_80000\")\n",
    "        self.controlnet_ckpt = os.path.join(ROOT , \"outputsV2\" , \"controlnet_ratio_lora_ckpt18000_layout80000\")\n",
    "\n",
    "        self.lora_path = os.path.join(ROOT , \"outputsV2\" , \"lora_loveda_sd15_r8\" , \"checkpoint-29000\")\n",
    "        self.lora_weight_name = \"pytorch_lora_weights.safetensors\"\n",
    "        self.lora_scale = 1.0\n",
    "\n",
    "        self.image_size = 1024\n",
    "        self.num_inference_steps_layout = 50\n",
    "        self.num_inference_steps_image = 50\n",
    "        self.guidance_scale = 3.5\n",
    "        self.guidance_rescale = 0.0\n",
    "        self.control_scale = 2.0  # default in sample_pair.py\n",
    "        self.seed0 = 123\n",
    "        self.dtype = \"fp16\"\n",
    "        self.device = \"cuda\"\n",
    "        self.sampler = \"dpmpp_2m\"\n",
    "        self.use_karras_sigmas = False\n",
    "        self.attention_slicing = \"auto\"  # set to None to disable\n",
    "        self.enable_xformers = False\n",
    "        self.vae_tiling = True\n",
    "        self.vae_slicing = False\n",
    "        self.capture_output = False  # True hides live tqdm bars but keeps logs\n",
    "\n",
    "        self.gpu_ids = [3, 4, 5]\n",
    "\n",
    "        self.run_id = \"1\"\n",
    "        self.save_root = os.path.join(ROOT,\"outputsV2\" , \"resultsgenerator_runs\")\n",
    "        self.outdir = os.path.join(self.save_root, self.run_id)\n",
    "        \n",
    "        pathlib.Path(self.outdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.init_mask = None\n",
    "        self.mask_format = \"loveda_raw\"  # loveda_raw or indexed\n",
    "        self.strength_layout = 0.0\n",
    "\n",
    "\n",
    "args = ARGS()\n",
    "print(\"OUTDIR:\", args.outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7704af6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/.local/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.6.2) or chardet (None)/charset_normalizer (3.4.4) doesn't match a supported version!\n",
      "  warnings.warn(\n",
      "/home/nvidia/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mpath:\n\u001b[1;32m     14\u001b[0m         sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, p)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sample_pair\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Allow sample_pair.main(args) in notebooks by temporarily overriding parse_args.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inspect\u001b[38;5;241m.\u001b[39msignature(sample_pair\u001b[38;5;241m.\u001b[39mmain)\u001b[38;5;241m.\u001b[39mparameters) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/SyntheticGen/src/scripts/sample_pair.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, ImageOps\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CLIPTextModel, CLIPTokenizer\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdiffusers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     AutoencoderKL,\n\u001b[1;32m     23\u001b[0m     ControlNetModel,\n\u001b[1;32m     24\u001b[0m     DDIMScheduler,\n\u001b[1;32m     25\u001b[0m     DDPMScheduler,\n\u001b[1;32m     26\u001b[0m     DPMSolverMultistepScheduler,\n\u001b[1;32m     27\u001b[0m     UNet2DConditionModel,\n\u001b[1;32m     28\u001b[0m     UNet2DModel,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_loveda\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_LOVEDA_CLASS_NAMES, build_palette\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/utils/import_utils.py:1007\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1006\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m-> 1007\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/utils/import_utils.py:1006\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1006\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1007\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/utils/import_utils.py:1016\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1016\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1019\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1020\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/data/inr/llm/.lib/diffusers/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/models/autoencoders/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautoencoder_asym_kl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsymmetricAutoencoderKL\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautoencoder_dc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoencoderDC\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautoencoder_kl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoencoderKL\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/models/autoencoders/autoencoder_asym_kl.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoencoderKLOutput\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelMixin\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvae\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoencoderMixin, DecoderOutput, DiagonalGaussianDistribution, Encoder, MaskConditionDecoder\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mAsymmetricAutoencoderKL\u001b[39;00m(ModelMixin, AutoencoderMixin, ConfigMixin):\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    Designing a Better Asymmetric VQGAN for StableDiffusion https://huggingface.co/papers/2306.04632 . A VAE model with\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    KL loss for encoding images into latents and decoding latent representations into images.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m            Synthesis with Latent Diffusion Models](https://huggingface.co/papers/2112.10752) paper.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/models/autoencoders/vae.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_activation\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention_processor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SpatialNorm\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_2d_blocks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     AutoencoderTinyBlock,\n\u001b[1;32m     27\u001b[0m     UNetMidBlock2D,\n\u001b[1;32m     28\u001b[0m     get_down_block,\n\u001b[1;32m     29\u001b[0m     get_up_block,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mEncoderOutput\u001b[39;00m(BaseOutput):\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m    Output of encoding method.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m            The encoded latent.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/models/unets/__init__.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_1d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UNet1DModel\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_2d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UNet2DModel\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_2d_condition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UNet2DConditionModel\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_3d_condition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UNet3DConditionModel\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/models/unets/unet_2d.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GaussianFourierProjection, TimestepEmbedding, Timesteps\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelMixin\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munet_2d_blocks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UNetMidBlock2D, get_down_block, get_up_block\n\u001b[1;32m     27\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mUNet2DOutput\u001b[39;00m(BaseOutput):\n\u001b[1;32m     29\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    The output of [`UNet2DModel`].\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m            The hidden states output from the last layer of the model.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/models/unets/unet_2d_blocks.py:36\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnormalization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdaGroupNorm\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresnet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     Downsample2D,\n\u001b[1;32m     28\u001b[0m     FirDownsample2D,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     Upsample2D,\n\u001b[1;32m     35\u001b[0m )\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdual_transformer_2d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DualTransformer2DModel\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer_2d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Transformer2DModel\n\u001b[1;32m     40\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/models/transformers/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_torch_available\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauraflow_transformer_2d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AuraFlowTransformer2DModel\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcogvideox_transformer_3d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CogVideoXTransformer3DModel\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconsisid_transformer_3d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConsisIDTransformer3DModel\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/models/transformers/auraflow_transformer_2d.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConfigMixin, register_to_config\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FromOriginalModelMixin, PeftAdapterMixin\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m USE_PEFT_BACKEND, logging, scale_lora_layers, unscale_lora_layers\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m maybe_allow_in_graph\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/utils/import_utils.py:1006\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1006\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1007\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/utils/import_utils.py:1016\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1016\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1019\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1020\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/data/inr/llm/.lib/diffusers/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/loaders/peft.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msafetensors\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroup_offloading\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _maybe_remove_and_reapply_group_offloading\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     MIN_PEFT_VERSION,\n\u001b[1;32m     28\u001b[0m     USE_PEFT_BACKEND,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     set_weights_and_activate_adapters,\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpeft_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _create_lora_config, _maybe_warn_for_unhandled_keys\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/hooks/__init__.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HookRegistry, ModelHook\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer_skip\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LayerSkipConfig, apply_layer_skip\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayerwise_casting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m apply_layerwise_casting, apply_layerwise_casting_hook\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyramid_attention_broadcast\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyramidAttentionBroadcastConfig, apply_pyramid_attention_broadcast\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msmoothed_energy_guidance_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SmoothedEnergyGuidanceConfig\n",
      "File \u001b[0;32m/data/inr/llm/DIFF_CD/Diffusor/diffusers/src/diffusers/hooks/layerwise_casting.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m _SHOULD_DISABLE_PEFT_INPUT_AUTOCAST \u001b[38;5;241m=\u001b[39m is_peft_available() \u001b[38;5;129;01mand\u001b[39;00m is_peft_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.14.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _SHOULD_DISABLE_PEFT_INPUT_AUTOCAST:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m disable_input_dtype_casting\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseTunerLayer\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mLayerwiseCastingHook\u001b[39;00m(ModelHook):\n",
      "File \u001b[0;32m/data/inr/llm/.lib/diffusers/lib/python3.10/site-packages/peft/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2023-present the HuggingFace Inc. team.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.18.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     MODEL_TYPE_TO_PEFT_MODEL_MAPPING,\n\u001b[1;32m     19\u001b[0m     AutoPeftModel,\n\u001b[1;32m     20\u001b[0m     AutoPeftModelForCausalLM,\n\u001b[1;32m     21\u001b[0m     AutoPeftModelForFeatureExtraction,\n\u001b[1;32m     22\u001b[0m     AutoPeftModelForQuestionAnswering,\n\u001b[1;32m     23\u001b[0m     AutoPeftModelForSeq2SeqLM,\n\u001b[1;32m     24\u001b[0m     AutoPeftModelForSequenceClassification,\n\u001b[1;32m     25\u001b[0m     AutoPeftModelForTokenClassification,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftConfig, PromptLearningConfig\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     PEFT_TYPE_TO_CONFIG_MAPPING,\n\u001b[1;32m     30\u001b[0m     PEFT_TYPE_TO_MIXED_MODEL_MAPPING,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     inject_adapter_in_model,\n\u001b[1;32m     34\u001b[0m )\n",
      "File \u001b[0;32m/data/inr/llm/.lib/diffusers/lib/python3.10/site-packages/peft/auto.py:32\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     AutoModel,\n\u001b[1;32m     23\u001b[0m     AutoModelForCausalLM,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     AutoTokenizer,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftConfig\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpeft_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     PeftModel,\n\u001b[1;32m     34\u001b[0m     PeftModelForCausalLM,\n\u001b[1;32m     35\u001b[0m     PeftModelForFeatureExtraction,\n\u001b[1;32m     36\u001b[0m     PeftModelForQuestionAnswering,\n\u001b[1;32m     37\u001b[0m     PeftModelForSeq2SeqLM,\n\u001b[1;32m     38\u001b[0m     PeftModelForSequenceClassification,\n\u001b[1;32m     39\u001b[0m     PeftModelForTokenClassification,\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TOKENIZER_CONFIG_NAME\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mother\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_file_exists_on_hf_hub\n",
      "File \u001b[0;32m/data/inr/llm/.lib/diffusers/lib/python3.10/site-packages/peft/peft_model.py:42\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QuestionAnsweringModelOutput, SequenceClassifierOutput, TokenClassifierOutput\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlora\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_alora_offsets_for_forward, get_alora_offsets_for_generate\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseTuner, BaseTunerLayer\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AuxiliaryTrainingWrapper\n",
      "File \u001b[0;32m/data/inr/llm/.lib/diffusers/lib/python3.10/site-packages/peft/tuners/__init__.py:39\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlokr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoKrConfig, LoKrModel\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlora\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     ArrowConfig,\n\u001b[1;32m     30\u001b[0m     EvaConfig,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     initialize_lora_eva_weights,\n\u001b[1;32m     38\u001b[0m )\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmiss\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MissConfig, MissModel\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MixedModel\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultitask_prompt_tuning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultitaskPromptEmbedding, MultitaskPromptTuningConfig, MultitaskPromptTuningInit\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:964\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:448\u001b[0m, in \u001b[0;36mcache_from_source\u001b[0;34m(path, debug_override, optimization)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:128\u001b[0m, in \u001b[0;36m_path_join\u001b[0;34m(*path_parts)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:128\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generate samples + visualize (pure Python, no shell/subprocess)\n",
    "\n",
    "import re\n",
    "import json\n",
    "import argparse\n",
    "import inspect\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure repo modules are importable in this notebook kernel\n",
    "DIFFUSERS_SRC = os.path.join(ROOT, \"diffusers\", \"src\")\n",
    "SYNTHETICGEN_ROOT = os.path.join(ROOT, \"SyntheticGen\")\n",
    "for p in [DIFFUSERS_SRC, SYNTHETICGEN_ROOT]:\n",
    "    if p not in sys.path:\n",
    "        sys.path.insert(0, p)\n",
    "\n",
    "from src.scripts import sample_pair\n",
    "\n",
    "# Allow sample_pair.main(args) in notebooks by temporarily overriding parse_args.\n",
    "if len(inspect.signature(sample_pair.main).parameters) == 0:\n",
    "    _sample_pair_main = sample_pair.main\n",
    "\n",
    "    def _main_with_args(parsed_args=None):\n",
    "        if parsed_args is None:\n",
    "            return _sample_pair_main()\n",
    "        original_parse_args = sample_pair.parse_args\n",
    "        try:\n",
    "            sample_pair.parse_args = lambda: parsed_args\n",
    "            return _sample_pair_main()\n",
    "        finally:\n",
    "            sample_pair.parse_args = original_parse_args\n",
    "\n",
    "    sample_pair.main = _main_with_args\n",
    "\n",
    "# ---- Notebook defaults (edit as needed) ----\n",
    "args = ARGS()\n",
    "\n",
    "args.outdir = os.path.join(ROOT, \"outputsV2\", \"results_generator\")\n",
    "args.gpu_ids = []\n",
    "args.init_mask = None\n",
    "args.strength_layout = 0.8\n",
    "args.strength_image = 0.8\n",
    "args.mask_format = \"indexed\"\n",
    "args.ignore_index = 255\n",
    "args.attention_slicing = False\n",
    "args.enable_xformers = False\n",
    "args.vae_tiling = False\n",
    "args.vae_slicing = False\n",
    "\n",
    "\n",
    "def _slugify(text: str) -> str:\n",
    "    text = (text or \"\").strip().lower()\n",
    "    text = re.sub(r\"[^a-z0-9]+\", \"-\", text)\n",
    "    return text.strip(\"-\")[:80] or \"case\"\n",
    "\n",
    "\n",
    "def _ratios_to_str(ratios):\n",
    "    if isinstance(ratios, str):\n",
    "        return ratios\n",
    "    if isinstance(ratios, dict):\n",
    "        return \",\".join(f\"{k}:{v}\" for k, v in ratios.items())\n",
    "    if isinstance(ratios, (list, tuple)):\n",
    "        return \",\".join(str(float(x)) for x in ratios)\n",
    "    raise TypeError(\"ratios must be dict, list, or str\")\n",
    "\n",
    "\n",
    "# ---- Define cases (edit these) ----\n",
    "# You can provide ratios as a list (length == num classes), dict (name->value), or a CSV string.\n",
    "USER_CASE = {\n",
    "    \"name\": \"custom\",\n",
    "    \"prompt\": \"a high-resolution satellite image\",\n",
    "    \"ratios\": [0.05, 0.2, 0.1, 0.05, 0.1, 0.25, 0.25],\n",
    "    \"seed\": args.seed0,\n",
    "}\n",
    "# Set USER_CASE = None to skip the custom case.\n",
    "cases = ([USER_CASE] if USER_CASE else []) + [\n",
    "    {\n",
    "        \"name\": \"baseline\",\n",
    "        \"prompt\": \"a high-resolution satellite image\",\n",
    "        \"ratios\": [0.05, 0.2, 0.1, 0.05, 0.1, 0.25, 0.25],\n",
    "        \"seed\": args.seed0,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"water_heavy\",\n",
    "        \"prompt\": \"a high-resolution satellite image, river delta, nadir view\",\n",
    "        \"ratios\": {\"water\": 0.45, \"road\": 0.15, \"building\": 0.10, \"forest\": 0.20, \"background\": 0.10},\n",
    "        \"seed\": args.seed0 + 1,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Write config for reproducibility\n",
    "Path(args.outdir).mkdir(parents=True, exist_ok=True)\n",
    "(Path(args.outdir) / \"cases.json\").write_text(json.dumps(cases, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def run_case(case: dict, idx: int, gpu_id=None) -> Path:\n",
    "    name = case.get(\"name\") or f\"case_{idx}\"\n",
    "    prompt = case.get(\"prompt\")\n",
    "    ratios = case.get(\"ratios\")\n",
    "    seed = int(case.get(\"seed\", args.seed0 + idx))\n",
    "\n",
    "    out_dir = Path(args.outdir) / f\"{idx:03d}_{_slugify(name)}\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if (out_dir / \"image.png\").is_file() and (out_dir / \"layout_color.png\").is_file():\n",
    "        print(f\"[skip] {out_dir}\")\n",
    "        return out_dir\n",
    "\n",
    "    device_str = str(args.device)\n",
    "    if gpu_id is not None and device_str.startswith(\"cuda\"):\n",
    "        device_str = f\"cuda:{int(gpu_id)}\"\n",
    "\n",
    "    sp_args = argparse.Namespace(\n",
    "        layout_ckpt=str(args.layout_ckpt),\n",
    "        controlnet_ckpt=str(args.controlnet_ckpt),\n",
    "        base_model=args.base_model,\n",
    "        lora_path=str(args.lora_path) if args.lora_path and Path(args.lora_path).exists() else None,\n",
    "        lora_weight_name=str(args.lora_weight_name),\n",
    "        lora_scale=float(args.lora_scale),\n",
    "        save_dir=str(out_dir),\n",
    "        ratios=_ratios_to_str(ratios),\n",
    "        ratios_json=None,\n",
    "        class_names_json=None,\n",
    "        prompt=str(prompt) if prompt else None,\n",
    "        init_image=case.get(\"init_image\", None),\n",
    "        init_mask=case.get(\"init_mask\", args.init_mask),\n",
    "        strength_layout=float(case.get(\"strength_layout\", args.strength_layout)),\n",
    "        strength_image=float(case.get(\"strength_image\", args.strength_image)),\n",
    "        ignore_index=int(case.get(\"ignore_index\", 255)),\n",
    "        mask_format=str(case.get(\"mask_format\", args.mask_format)),\n",
    "        seg_ckpt=case.get(\"seg_ckpt\", None),\n",
    "        seg_arch=str(case.get(\"seg_arch\", \"simple\")),\n",
    "        hist_guidance_scale=float(case.get(\"hist_guidance_scale\", 0.0)),\n",
    "        hist_guidance_temp=float(case.get(\"hist_guidance_temp\", 1.0)),\n",
    "        guidance_scale=float(case.get(\"guidance_scale\", args.guidance_scale)),\n",
    "        guidance_rescale=float(case.get(\"guidance_rescale\", args.guidance_rescale)),\n",
    "        control_scale=float(case.get(\"control_scale\", args.control_scale)),\n",
    "        attention_slicing=case.get(\"attention_slicing\", args.attention_slicing),\n",
    "        enable_xformers=bool(case.get(\"enable_xformers\", args.enable_xformers)),\n",
    "        vae_tiling=bool(case.get(\"vae_tiling\", args.vae_tiling)),\n",
    "        vae_slicing=bool(case.get(\"vae_slicing\", args.vae_slicing)),\n",
    "        use_karras_sigmas=bool(case.get(\"use_karras_sigmas\", args.use_karras_sigmas)),\n",
    "        sampler=str(case.get(\"sampler\", args.sampler)),\n",
    "        num_inference_steps_layout=int(case.get(\"num_inference_steps_layout\", args.num_inference_steps_layout)),\n",
    "        num_inference_steps_image=int(case.get(\"num_inference_steps_image\", args.num_inference_steps_image)),\n",
    "        image_size=int(case.get(\"image_size\", args.image_size)),\n",
    "        seed=seed,\n",
    "        dtype=str(case.get(\"dtype\", args.dtype)),\n",
    "        device=device_str,\n",
    "    )\n",
    "\n",
    "    print(f\"[run] {idx:03d} {name} -> {out_dir} (device={device_str})\")\n",
    "    sample_pair.main(sp_args)\n",
    "    return out_dir\n",
    "\n",
    "\n",
    "# ---- Run ----\n",
    "results = []\n",
    "gpu_ids = list(args.gpu_ids) if args.gpu_ids else [None]\n",
    "for i, case in enumerate(cases):\n",
    "    results.append(run_case(case, i, gpu_id=gpu_ids[i % len(gpu_ids)]))\n",
    "\n",
    "print(\"Done:\")\n",
    "for p in results:\n",
    "    print(\" -\", p)\n",
    "\n",
    "\n",
    "# ---- Visualize ----\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def _compute_hard_ratios(layout_path: Path, num_classes: int, ignore_index: int = 255):\n",
    "    arr = np.array(Image.open(layout_path))\n",
    "    valid = arr != ignore_index\n",
    "    total = int(valid.sum())\n",
    "    if total == 0:\n",
    "        return np.zeros((num_classes,), dtype=np.float32)\n",
    "    counts = np.bincount(arr[valid].reshape(-1), minlength=num_classes).astype(np.float32)\n",
    "    return counts / float(total)\n",
    "\n",
    "\n",
    "def show_result(out_dir: Path):\n",
    "    meta_path = out_dir / \"metadata.json\"\n",
    "    meta = json.loads(meta_path.read_text(encoding=\"utf-8\")) if meta_path.is_file() else {}\n",
    "\n",
    "    layout_color = Image.open(out_dir / \"layout_color.png\").convert(\"RGB\")\n",
    "    image = Image.open(out_dir / \"image.png\").convert(\"RGB\")\n",
    "\n",
    "    title = meta.get(\"prompt\", \"\")\n",
    "    ratios = meta.get(\"ratios\")\n",
    "    class_names = meta.get(\"class_names\")\n",
    "\n",
    "    if class_names:\n",
    "        num_classes = len(class_names)\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        axs[0].imshow(layout_color)\n",
    "        axs[0].set_title(\"layout_color.png\")\n",
    "        axs[0].axis(\"off\")\n",
    "        axs[1].imshow(image)\n",
    "        axs[1].set_title(\"image.png\")\n",
    "        axs[1].axis(\"off\")\n",
    "\n",
    "        r_hat = _compute_hard_ratios(out_dir / \"layout.png\", num_classes=num_classes)\n",
    "        x = np.arange(num_classes)\n",
    "        if ratios is not None:\n",
    "            axs[2].bar(x - 0.2, ratios, width=0.4, label=\"target\")\n",
    "        axs[2].bar(x + 0.2, r_hat, width=0.4, label=\"hard\")\n",
    "        axs[2].set_ylim(0.0, 1.0)\n",
    "        axs[2].set_title(\"ratios\")\n",
    "        axs[2].set_xticks(x)\n",
    "        axs[2].set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "        axs[2].legend()\n",
    "    else:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        axs[0].imshow(layout_color)\n",
    "        axs[0].set_title(\"layout_color.png\")\n",
    "        axs[0].axis(\"off\")\n",
    "        axs[1].imshow(image)\n",
    "        axs[1].set_title(\"image.png\")\n",
    "        axs[1].axis(\"off\")\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for out_dir in results:\n",
    "    show_result(Path(out_dir))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
